{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dawid\\Desktop\\kurs\\jdszr4-animalsi\\wino\n"
     ]
    }
   ],
   "source": [
    "#sciezka z danymi\n",
    "%cd \"C:\\Users\\Dawid\\Desktop\\kurs\\jdszr4-animalsi\\wino\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glowne biblioteki\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from time import time \n",
    "from winsound import Beep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lista zmiennych: \n",
      " ['X', 'Y', 'X_train_all', 'X_test', 'Y_train_all', 'Y_test', 'X_train_reduced', 'X_val', 'Y_train_reduced', 'Y_val', 'X_train_all_scaled', 'X_test_scaled', 'X_val_scaled', 'X_train_reduced_scaled', 'X_train_all_scaled_PCA', 'X_test_scaled_PCA', 'X_train_reduced_scaled_PCA', 'X_val_scaled_PCA']\n"
     ]
    }
   ],
   "source": [
    "#wlasny modul\n",
    "from dane.dane_wsadowe import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Prosty model lasow losowych jako benchmark**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) dane nieprzetworzone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc train:  1.0 \n",
      " acc val:  0.8125\n"
     ]
    }
   ],
   "source": [
    "#wyjdzmy od prostego modelu na domyslnych parametrach\n",
    "model_rf1 = RandomForestClassifier()\n",
    "model_rf1.fit(X_train_reduced,Y_train_reduced)\n",
    "pred_rf1 = model_rf1.predict(X_val)\n",
    "\n",
    "#ocena modelu na danych treningowych i testowych \n",
    "print(\"acc train: \",round(model_rf1.score(X_train_reduced, Y_train_reduced),4), \"\\n\",\n",
    "      \"acc val: \", round(model_rf1.score(X_val, Y_val),4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.81      0.94      0.87       101\n",
      "           3       0.45      0.25      0.32        20\n",
      "\n",
      "    accuracy                           0.78       128\n",
      "   macro avg       0.42      0.40      0.40       128\n",
      "weighted avg       0.71      0.78      0.74       128\n",
      "\n",
      "[[ 0  7  0]\n",
      " [ 0 95  6]\n",
      " [ 0 15  5]]\n"
     ]
    }
   ],
   "source": [
    "#ocena jakosci modelu nr 1\n",
    "rf1_cnf_matrix = confusion_matrix(Y_val, pred_rf1)\n",
    "rf1_cnf_raport = classification_report(Y_val, pred_rf1)\n",
    "print(rf1_cnf_raport)\n",
    "print(rf1_cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocena pierwszego modelu, model jak mozna bylo się spodziewać dobrze przewiduje klase najbardziej liczna, a w ogóle nie trafią w klase 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) dane przeskalowane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wyjdzmy od prostego modelu na domyslnych parametrach\n",
    "model_rf2 = RandomForestClassifier()\n",
    "model_rf2.fit(X_train_reduced_scaled,Y_train_reduced)\n",
    "pred_rf2 = model_rf2.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.82      0.93      0.87       101\n",
      "           3       0.50      0.35      0.41        20\n",
      "\n",
      "    accuracy                           0.79       128\n",
      "   macro avg       0.44      0.43      0.43       128\n",
      "weighted avg       0.73      0.79      0.75       128\n",
      "\n",
      "[[ 0  7  0]\n",
      " [ 0 94  7]\n",
      " [ 0 13  7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dawid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#ocena jakosci modelu nr 2\n",
    "rf2_cnf_matrix = confusion_matrix(Y_val, pred_rf2)\n",
    "rf2_cnf_raport = classification_report(Y_val, pred_rf2)\n",
    "print(rf2_cnf_raport)\n",
    "print(rf2_cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy przeskalowanych danych poprawił nam się nieznacznie współczynik F1 dla klasy 3, ale wciąż nie udało nam się sklasyfikować żadnej obserwacji jako klasa 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) dane PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wyjdzmy od prostego modelu na domyslnych parametrach\n",
    "model_rf3 = RandomForestClassifier()\n",
    "model_rf3.fit(X_train_reduced_scaled_PCA,Y_train_reduced)\n",
    "pred_rf3 = model_rf3.predict(X_val_scaled_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.14      0.25         7\n",
      "           2       0.82      0.93      0.87       101\n",
      "           3       0.46      0.30      0.36        20\n",
      "\n",
      "    accuracy                           0.79       128\n",
      "   macro avg       0.76      0.46      0.50       128\n",
      "weighted avg       0.78      0.79      0.76       128\n",
      "\n",
      "[[ 1  6  0]\n",
      " [ 0 94  7]\n",
      " [ 0 14  6]]\n"
     ]
    }
   ],
   "source": [
    "#ocena jakosci modelu nr 3\n",
    "rf3_cnf_matrix = confusion_matrix(Y_val, pred_rf3)\n",
    "rf3_cnf_raport = classification_report(Y_val, pred_rf3)\n",
    "print(rf3_cnf_raport)\n",
    "print(rf3_cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten wariant w końcu sklasyfikował nam cos poprawnie dla klasy 1, ale w większości błędnie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Znajdzmy najlepsze parametry dla tego modelu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zacznijmy od małego zestawu, by dostrzec czy jest w ogóle jakas poprawa\n",
    "params_rf1 = {\"max_depth\"        :list(range(2, 15, 2)),\n",
    "              \"n_estimators\"     :list(range(50,211,40)),\n",
    "              \"min_samples_leaf\" :list(range(2, 21, 3)),\n",
    "              \"max_features\"     :[3,6,9,None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=  0   # policzymy ile jest mozliwych kombinacji parametrow\n",
    "for j in params_rf1.values():\n",
    "    s=len(j)\n",
    "    r += s\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) model oparty na nieprzetworzonych danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zdefiniujmy obiekt sprawdzajacy nasze parametry\n",
    "grid_search1 =  GridSearchCV(RandomForestClassifier(),param_grid = params_rf1,cv =5,verbose = 1,n_jobs = 1,scoring = make_scorer(f1_score, average = \"macro\")).fit(X_train_all,Y_train_all)\n",
    "Beep(400,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 14, 'max_features': 3, 'min_samples_leaf': 2, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# sprawdzmy nasz najlepszy zestaw parametrow\n",
    "print(grid_search1.best_params_)\n",
    "\n",
    "model_rf4 = grid_search1.best_estimator_\n",
    "model_rf4.fit(X_train_all,Y_train_all)\n",
    "\n",
    "pred_rf4 = model_rf4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.09      0.17        11\n",
      "           2       0.89      0.96      0.92       263\n",
      "           3       0.69      0.54      0.61        46\n",
      "\n",
      "    accuracy                           0.87       320\n",
      "   macro avg       0.86      0.53      0.57       320\n",
      "weighted avg       0.87      0.87      0.85       320\n",
      "\n",
      "[[  1  10   0]\n",
      " [  0 252  11]\n",
      " [  0  21  25]]\n"
     ]
    }
   ],
   "source": [
    "#ocena jakosci modelu z wybranymi najlepszymi parametrami\n",
    "rf4_cnf_matrix = confusion_matrix(Y_test, pred_rf4)\n",
    "rf4_cnf_raport = classification_report(Y_test, pred_rf4)\n",
    "print(rf4_cnf_raport)\n",
    "print(rf4_cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nasz model znacznie poprawił precyzje dla klasy 2 i 3, jednak wciaz słabo klasyfikuje klase 1szą. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) model oparty na przeskalowanych danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 980 candidates, totalling 4900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=2)]: Done 1246 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=2)]: Done 1796 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=2)]: Done 2446 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=2)]: Done 3196 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=2)]: Done 4046 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=2)]: Done 4900 out of 4900 | elapsed: 31.5min finished\n"
     ]
    }
   ],
   "source": [
    "#zdefiniujmy obiekt sprawdzajacy nasze parametry\n",
    "grid_search2 =  GridSearchCV(RandomForestClassifier(),param_grid = params_rf1,cv =5,verbose = 1,n_jobs = 2,scoring = make_scorer(f1_score, average = \"macro\")).fit(X_train_all_scaled,Y_train_all)\n",
    "Beep(400,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 14, 'max_features': None, 'min_samples_leaf': 2, 'n_estimators': 130}\n"
     ]
    }
   ],
   "source": [
    "# sprawdzmy nasz najlepszy zestaw parametrow\n",
    "print(grid_search2.best_params_)\n",
    "\n",
    "model_rf5 = grid_search2.best_estimator_\n",
    "model_rf5.fit(X_train_all_scaled,Y_train_all)\n",
    "\n",
    "pred_rf5 = model_rf5.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.09      0.15        11\n",
      "           2       0.89      0.94      0.92       263\n",
      "           3       0.64      0.54      0.59        46\n",
      "\n",
      "    accuracy                           0.86       320\n",
      "   macro avg       0.68      0.53      0.55       320\n",
      "weighted avg       0.84      0.86      0.84       320\n",
      "\n",
      "[[  1  10   0]\n",
      " [  1 248  14]\n",
      " [  0  21  25]]\n"
     ]
    }
   ],
   "source": [
    "#ocena jakosci modelu z wybranymi najlepszymi parametrami\n",
    "rf5_cnf_matrix = confusion_matrix(Y_test, pred_rf5)\n",
    "rf5_cnf_raport = classification_report(Y_test, pred_rf5)\n",
    "print(rf5_cnf_raport)\n",
    "print(rf5_cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy przeskalowanych danych nie widzimy poprawy, wręcz delikatne pogorszenie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) dane PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 980 candidates, totalling 4900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=3)]: Done 1244 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=3)]: Done 1794 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=3)]: Done 2444 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=3)]: Done 3194 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=3)]: Done 4044 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=3)]: Done 4900 out of 4900 | elapsed: 23.0min finished\n"
     ]
    }
   ],
   "source": [
    "#zdefiniujmy obiekt sprawdzajacy nasze parametry\n",
    "grid_search3 =  GridSearchCV(RandomForestClassifier(),param_grid = params_rf1,cv =5,verbose = 1,n_jobs = 3,scoring = make_scorer(f1_score, average = \"macro\")).fit(X_train_all_scaled_PCA,Y_train_all)\n",
    "Beep(400,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 14, 'max_features': None, 'min_samples_leaf': 2, 'n_estimators': 170}\n"
     ]
    }
   ],
   "source": [
    "# sprawdzmy nasz najlepszy zestaw parametrow\n",
    "print(grid_search3.best_params_)\n",
    "\n",
    "model_rf6 = grid_search3.best_estimator_\n",
    "model_rf6.fit(X_train_all_scaled_PCA,Y_train_all)\n",
    "\n",
    "pred_rf6 = model_rf6.predict(X_test_scaled_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.89      0.94      0.91       263\n",
      "           3       0.63      0.52      0.57        46\n",
      "\n",
      "    accuracy                           0.85       320\n",
      "   macro avg       0.51      0.49      0.49       320\n",
      "weighted avg       0.82      0.85      0.83       320\n",
      "\n",
      "[[  0  10   1]\n",
      " [  2 248  13]\n",
      " [  0  22  24]]\n"
     ]
    }
   ],
   "source": [
    "#ocena jakosci modelu z wybranymi najlepszymi parametrami\n",
    "rf6_cnf_matrix = confusion_matrix(Y_test, pred_rf6)\n",
    "rf6_cnf_raport = classification_report(Y_test, pred_rf6)\n",
    "print(rf6_cnf_raport)\n",
    "print(rf6_cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nasz model przy danych po PCA odnotował gorsze wyniki niż bez skalowania."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Popracujmy nad niezbalansowaniem klas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#znajdzmy najpierw dla danych nieprzeskalowanych mozliwie lepszy zestaw parametrow, \n",
    "#na podstawie wnioskow z juz przeprowadzonych obliczen.\n",
    "\n",
    "params_rf2 = {\"max_depth\"        :list(range(14, 25, 2)),\n",
    "              \"n_estimators\"     :list(range(50,221,40)),\n",
    "              \"min_samples_leaf\" :list(range(2, 6)),\n",
    "              \"max_features\"     :[3,4,9,11,None]              \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 600 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=2)]: Done 1246 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=2)]: Done 1796 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=2)]: Done 2446 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=2)]: Done 3000 out of 3000 | elapsed: 27.3min finished\n"
     ]
    }
   ],
   "source": [
    "#zdefiniujmy obiekt sprawdzajacy nasze parametry\n",
    "grid_search4 =  GridSearchCV(RandomForestClassifier(),param_grid = params_rf2,cv =5,verbose = 1,n_jobs = 2,scoring = make_scorer(f1_score, average = \"macro\")).fit(X_train_all,Y_train_all)\n",
    "Beep(400,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 18, 'max_features': None, 'min_samples_leaf': 2, 'n_estimators': 170}\n"
     ]
    }
   ],
   "source": [
    "# sprawdzmy nasz najlepszy zestaw parametrow\n",
    "print(grid_search4.best_params_)\n",
    "\n",
    "model_rf7 = grid_search4.best_estimator_\n",
    "model_rf7.fit(X_train_all,Y_train_all)\n",
    "\n",
    "pred_rf7 = model_rf7.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.88      0.96      0.92       265\n",
      "           3       0.66      0.43      0.52        44\n",
      "\n",
      "    accuracy                           0.86       320\n",
      "   macro avg       0.51      0.46      0.48       320\n",
      "weighted avg       0.82      0.86      0.83       320\n",
      "\n",
      "[[  0  11   0]\n",
      " [  0 255  10]\n",
      " [  0  25  19]]\n"
     ]
    }
   ],
   "source": [
    "#ocena jakosci modelu z wybranymi najlepszymi parametrami\n",
    "rf7_cnf_matrix = confusion_matrix(Y_test, pred_rf7)\n",
    "rf7_cnf_raport = classification_report(Y_test, pred_rf7)\n",
    "print(rf7_cnf_raport)\n",
    "print(rf7_cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystujac pelna ilosc zmiennych w naszym modelu poprawilismy klasyfikacje dla klasy 3, ale to nadal nie jest idealna klasyfikacja dla klasy 3 i slaba dla klasy 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dobierzmy jeszcze do naszego najlepszego modelu najbardziej optymalny zestaw wag\n",
    "weights = np.linspace(0.05,0.95,50)\n",
    "params_weight1 = {\"class_weight\": [{1:x, 2:y,3:1-x-y} for x in weights for y in weights  if x+y <1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1225 candidates, totalling 6125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=3)]: Done 1244 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=3)]: Done 1794 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=3)]: Done 2444 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=3)]: Done 3194 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=3)]: Done 4044 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=3)]: Done 4994 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=3)]: Done 6044 tasks      | elapsed: 39.3min\n",
      "[Parallel(n_jobs=3)]: Done 6125 out of 6125 | elapsed: 39.8min finished\n"
     ]
    }
   ],
   "source": [
    "#zdefiniujmy obiekt sprawdzajacy nasze losowane wagi na ostatnim wyliczonym modelu\n",
    "grid_search5 =  GridSearchCV(grid_search4.best_estimator_,param_grid = params_weight1,cv =5,verbose = 1,n_jobs = 3,scoring = make_scorer(f1_score, average = \"macro\")).fit(X_train_all,Y_train_all)\n",
    "Beep(400,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': {1: 0.7295918367346939, 2: 0.05, 3: 0.22040816326530616}}\n"
     ]
    }
   ],
   "source": [
    "# sprawdzmy jaki jest nasz najlepszy zestaw wag\n",
    "print(grid_search5.best_params_)\n",
    "\n",
    "model_rf8 = grid_search5.best_estimator_\n",
    "model_rf8.fit(X_train_all,Y_train_all)\n",
    "\n",
    "pred_rf8 = model_rf8.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.09      0.13        11\n",
      "           2       0.89      0.92      0.90       263\n",
      "           3       0.59      0.57      0.58        46\n",
      "\n",
      "    accuracy                           0.84       320\n",
      "   macro avg       0.56      0.52      0.54       320\n",
      "weighted avg       0.82      0.84      0.83       320\n",
      "\n",
      "[[  1  10   0]\n",
      " [  4 241  18]\n",
      " [  0  20  26]]\n"
     ]
    }
   ],
   "source": [
    "#ocena jakosci modelu z wybranymi najlepszymi wagami i parametrami\n",
    "rf8_cnf_matrix = confusion_matrix(Y_test, pred_rf8)\n",
    "rf8_cnf_raport = classification_report(Y_test, pred_rf8)\n",
    "print(rf8_cnf_raport)\n",
    "print(rf8_cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dziwne, ale model zaproponował nam nielogiczne rozłozenie wag per klasa, wpłynęło to pozytywnie tylko na klasę 2, pozostałe klasy bez zmian.\n",
    "Pozostaje nam tylko sprawdzic pole pod krzywa AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={1: 0.7295918367346939, 2: 0.05,\n",
       "                                     3: 0.22040816326530616},\n",
       "                       max_depth=14, max_features=11, min_samples_leaf=2,\n",
       "                       n_estimators=90)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search5.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spróbujmy zastosowac inna walidacje krzyżową, właściwą dla niezbalansowanych danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1225 candidates, totalling 4900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed: 24.5min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed: 32.4min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed: 41.3min\n",
      "[Parallel(n_jobs=4)]: Done 4900 out of 4900 | elapsed: 49.7min finished\n"
     ]
    }
   ],
   "source": [
    "#zdefiniujmy obiekt sprawdzajacy nasze losowane wagi na ostatnim wyliczonym modelu\n",
    "grid_search6 =  GridSearchCV(grid_search4.best_estimator_,param_grid = params_weight1,cv =skf,verbose = 1,n_jobs = 3,scoring = make_scorer(balanced_accuracy_score)).fit(X_train_all,Y_train_all)\n",
    "Beep(400,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': {1: 0.5826530612244898, 2: 0.08673469387755102, 3: 0.3306122448979592}}\n"
     ]
    }
   ],
   "source": [
    "# sprawdzmy nasz najlepszy zestaw parametrow\n",
    "print(grid_search6.best_params_)\n",
    "\n",
    "model_rf9 = grid_search6.best_estimator_\n",
    "model_rf9.fit(X_train_all,Y_train_all)\n",
    "\n",
    "pred_rf9 = model_rf9.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.90      0.95      0.93       265\n",
      "           3       0.68      0.59      0.63        44\n",
      "\n",
      "    accuracy                           0.87       320\n",
      "   macro avg       0.53      0.52      0.52       320\n",
      "weighted avg       0.84      0.87      0.85       320\n",
      "\n",
      "[[  0  11   0]\n",
      " [  0 253  12]\n",
      " [  0  18  26]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dawid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#ocena jakosci modelu z wybranymi najlepszymi wagami i parametrami\n",
    "rf9_cnf_matrix = confusion_matrix(Y_test, pred_rf9)\n",
    "rf9_cnf_raport = classification_report(Y_test, pred_rf9)\n",
    "print(rf9_cnf_raport)\n",
    "print(rf9_cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nasz model nie jest w stanie przewidzieć klasy 1, spróbujmy wykorzystać inny model lub zmienić klasy decyzyjne, tak aby skorzystać z klasyfikacji binarnej."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
